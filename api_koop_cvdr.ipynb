{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/WetSuiteLeiden/data-collection/blob/master/api_koop_cvdr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "Show how we fetch data from the CVDR repository to be used to create our corresponding datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some API notes (you can skip this)\n",
    "\n",
    "There currently seem to be approximately 85k regulations (approximately 310k documents if you include all versions).\n",
    "\n",
    "\n",
    "Standard metadata fields are [declared to be](https://standaarden.overheid.nl/cvdr): \n",
    "* **identifier** - CVDR-ID (_including_ version number)\n",
    "\n",
    "* **title**\n",
    "* **alternative** (...title)\n",
    "  * there can be multiple. Present on most but not all records.\n",
    "  * seems to often be the same as title (VERIFY)\n",
    "\n",
    "* **subject**\n",
    "  * there can be multiple. Present on most but not all records.\n",
    "  * apparently a smallish controlled keyword set, including e.g. 'bestuur en recht', 'financiÃ«n en economie', 'maatschappelijke zorg en welzijn', 'openbare orde en veiligheid', 'ruimtelijke ordening, verkeer en vervoer', 'milieu', 'volkshuisvesting en woningbouw', 'onderwijs', 'personeel en organisatie'm 'algemeen'\n",
    "\n",
    "* **creator**\n",
    "  * specifically named gemeentes, waterschappen, omgevingsdiensten, etc.\n",
    "  * the `scheme` attribute mentions what kind it is\n",
    "\n",
    "* **publisher** (Uitgever)\n",
    "\n",
    "* **source** (Bron / Oorsprong)\n",
    "  * there can be multiple\n",
    "  * seems to be the law this regulation is applying (VERIFY) (grondslag of bevoegdheid)\n",
    "  * Seems to often refer to something general like the Gemeentewet, Provinciewet, but sometimes more specific things (e.g. Algemene wet bestuursrecht, Archiefwet, Winkeltijdenwet, Participatiewet, Wet op het primair onderwijs, Wet maatschappelijke ondersteuning, Ambtenarenwet, Wet algemene bepalingen omgevingsrecht, Wet ruimtelijke ordening, etc.)\n",
    "  * the `resourceIdentifier` attribute is a URL, the node text is a description\n",
    "  * seems a little free-form\n",
    "\n",
    "\n",
    "* **issued** (Uitgiftedatum)\n",
    "  * there can be multiple\n",
    "* modified (Wijzigingsdatum)\n",
    "\n",
    "* **isRatifiedBy** (Beslisser)\n",
    "  * there can be multiple\n",
    "  * seems a smallish controlled keyword set, including values like 'gemeenteraad', 'college van burgemeester en wethouders', 'algemeen bestuur', 'dagelijks bestuur', 'burgemeester', 'gemandateerde functionaris', 'gedeputeerde staten', 'geattribueerde functionaris', 'gedelegeerde functionaris', 'heffingsambtenaar', 'provinciale staten', 'invorderingsambtenaar', 'dijkgraaf', 'deelraad'\n",
    "  * the `scheme` attribute mentions what kind it is\n",
    "\n",
    "* **isFormatOf** - seems to refer to the the place it was published (isFormatOf pointing out that this is a (non-authoritative? (VERIFY)) copy of the same information)\n",
    "  * there can be multiple. Present on most but not all records.\n",
    "  * mostly specific [Gmb](#glossary_g), [Prb](#glossary_p), [Bgr](#glossary_b), [Wsb](#glossary_w) references, but also includes local newsletters, and a number of unknowns and not-applicables\n",
    "  * seems to also be filled in _somewhat_ free-form\n",
    "  * the `resourceIdentifier` attribute is a URL, the node text is a description\n",
    "\n",
    "\n",
    "* language - seems to just be 'nl'? (VERIFY)\n",
    "\n",
    "* rights - seems to just be the text 'De tekst in dit document is vrij van auteursrecht en databankrecht' (VERIFY)\n",
    "  * Present on most but not all records.\n",
    "\n",
    "* format - actually seems unused? (VERIFY)\n",
    "\n",
    "* **type** (apparently always 'regeling')\n",
    "  * the `scheme` attribute mentions what kind it is\n",
    "\n",
    "\n",
    "But there's a bunch more in the database - that are only present on a subset of records - including:\n",
    "* spatial - where it applies (often the same as creator?)\n",
    "* betreft\n",
    "* onderwerp\n",
    "* kenmerk\n",
    "* externeBijlage\n",
    "* redactioneleToevoeging\n",
    "* gedelegeerdeRegelgeving\n",
    "* uitwerkingtredingDatum\n",
    "* terugwerkendekrachtDatum\n",
    "* license (rare)\n",
    "<!-- \n",
    "\n",
    "in a sample:\n",
    " {'identifier': 19999, 'title': 19999, 'language': 19999, 'type': 19999, 'creator': 19999, 'modified': 19999, 'issued': 19999, 'source': 19999, \n",
    "  'inwerkingtredingDatum': 19999, 'betreft': 19999, 'isRatifiedBy': 19999, 'kenmerk': 19999, \n",
    "  'isFormatOf': 19962, 'alternative': 19515, 'subject': 19965, 'rights': 19987,  \n",
    "  'spatial': 16338, 'uitwerkingtredingDatum': 13048, 'gedelegeerdeRegelgeving': 7038, 'redactioneleToevoeging': 12810, 'onderwerp': 5364, 'terugwerkendekrachtDatum': 2355, 'externeBijlage': 1636, 'license': 3})\n",
    "\n",
    "\n",
    "Contents\n",
    "\n",
    "regeling/aanhef\n",
    "regeling/regeling-tekst\n",
    "regeling/regeling-sluiting\n",
    "regeling/bijlage (relative URL, absolute-ized relative to https://repository.officiele-overheidspublicaties.nl/)\n",
    "\n",
    "\n",
    "Documents seem to have references to \n",
    ": laws (BWB-ID)\n",
    ": officielebekendmakingen in prb, gmb, and others\n",
    "\n",
    "-->\n",
    "\n",
    "\n",
    "See also:\n",
    "* https://www.koopoverheid.nl/voor-overheden/gemeenten-provincies-en-waterschappen/cvdr/handleiding-cvdr (documentation for the input app, but explains a lot of useful things in passing)\n",
    "* https://www.koopoverheid.nl/binaries/koop/documenten/instructies/2017/10/23/cvdr-handleiding-deel-6-deel-6-metadata-xml-schema-en-webservices/IPM_dr_4_0_deel_6-Metadata_XML-schema_Webservices-1.pdf\n",
    "  * (the webservice it mentions seems to not exist anymore?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, datetime, random, time, pprint\n",
    "\n",
    "import wetsuite.helpers.notebook\n",
    "import wetsuite.helpers.localdata\n",
    "import wetsuite.datacollect.koop_sru \n",
    "import wetsuite.helpers.date\n",
    "import wetsuite.helpers.etree\n",
    "import wetsuite.helpers.koop_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store to put downloads into:\n",
    "cvdr_fetched = wetsuite.helpers.localdata.LocalKV( 'cvdr_fetched.db', str, bytes )\n",
    "\n",
    "# out of interest  (can take a few seconds once it's large, because get_num_items walks through everything)\n",
    "#cvdr_fetched.summary(get_num_items=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dcterms.modified >= 2024-10-28']\n"
     ]
    }
   ],
   "source": [
    "# right now this is simplified to just one 'recent stuff please'   (we previously collected a number of queries to pose)\n",
    "queries = []\n",
    "\n",
    "# IF you want to fetch a lot of content, then you probably split many years into shorter spans:  (for reference, there are usually 20 to 250 items per day)\n",
    "# for from_date, to_date in wetsuite.helpers.date.date_ranges( from_date=datetime.date( 2000, 1, 1 ),  to_date=datetime.date.today(), increment_days=50, strftime_format=\"%Y-%m-%d\" ):\n",
    "#     queries.append( f'dcterms.modified>={from_date} and dcterms.modified<={to_date}' ) # TODO: check whether there is a better field than modified\n",
    "\n",
    "# IF you only care to update with recent changes:\n",
    "#   (note: we treat this as \"fetch documents that were mentioned\", \n",
    "#          not as a \"re-fetch things that were changed\" )\n",
    "some_time_ago = datetime.date.today() - datetime.timedelta( days=21 )\n",
    "queries.append( f'dcterms.modified >= {some_time_ago.strftime(\"%Y-%m-%d\")}' )\n",
    "\n",
    "print( queries )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post those queries, fetch any referenced documents we didn't already have\n",
    "# will not be fast because we are keeping to some basic netiquette and rate limiting (_at all_, not even properly)\n",
    "\n",
    "sru_cvdr = wetsuite.datacollect.koop_sru.CVDR()\n",
    "\n",
    "for query in queries:\n",
    "    print( f'Search: {query}' )\n",
    "    sru_cvdr.search_retrieve( query ) # purely for the number of records, itself only for the progress bar\n",
    "    numrecs = sru_cvdr.num_records()\n",
    "    pbar = wetsuite.helpers.notebook.progress_bar( numrecs, description='fetching' )\n",
    "\n",
    "    count_cached, count_fetched, count_error = 0, 0, 0\n",
    "\n",
    "    def cvdr_callback( record_node ):\n",
    "        ''' Read search result records, pick out the URLs to fetch and fetch them. \n",
    "            Is a local function because we count per query, in a slightly weirdly scoped way '''\n",
    "        #print( wetsuite.helpers.etree.debug_color( record_node ) ) # for later reference, if you want to extract more out of these search records\n",
    "        global count_cached, count_fetched, count_error\n",
    "\n",
    "        merged = wetsuite.helpers.koop_parse.cvdr_meta( record_node, flatten=True ) \n",
    "        # using flatten is a little creative for something that needs to be a precise value (see cvdr_meta's docstring) but in current use it is valid.\n",
    "        #pprint.pprint( merged )\n",
    "\n",
    "        for resource_name, resource_key in ( \n",
    "            ('XML',  'publicatieurl_xml'),\n",
    "            ('HTML', 'publicatieurl_xhtml'),\n",
    "        ):\n",
    "            if resource_key not in merged:\n",
    "                print('SKIP: no %r in %r'%(resource_key, merged))\n",
    "            else:\n",
    "                try:\n",
    "                    _, came_from_cache = wetsuite.helpers.localdata.cached_fetch( cvdr_fetched, merged[ resource_key] ) # we currently care only about the XML it links to\n",
    "                    if not came_from_cache:\n",
    "                        count_fetched += 1\n",
    "                        time.sleep( 2 ) # be somewhat nice to the servers\n",
    "                    else:\n",
    "                        count_cached += 1\n",
    "                # mainly expecting 404, 500\n",
    "                except ValueError as e:\n",
    "                    count_error += 1\n",
    "                    print( \"ERROR downloading %s: %s  for %r\"%(resource_name, e, merged[resource_key]))\n",
    "                    time.sleep( 20 ) # be somewhat nicer to the servers\n",
    "\n",
    "        pbar.value       += 1\n",
    "        pbar.description  = f'{count_fetched} fetched, {count_cached} cached' # , {count_error} errors\n",
    "\n",
    "    try:\n",
    "        sru_cvdr.search_retrieve_many( query, at_a_time=500, up_to=50000, callback=cvdr_callback)\n",
    "\n",
    "    except ValueError as e:\n",
    "        count_error += 1\n",
    "        print( \"ERROR querying %s: %s\"%(query, e) )\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset\n",
    "\n",
    "We'll spare you the full contents of that store,\n",
    "because it contains most versions of most things, \n",
    "is even more overcomplete than that because of past experiments they have done,\n",
    "and probably not something you want to fetch fully for the sheer size of it.\n",
    "\n",
    "Mostly for our own reference, it contains keys that are URLs like:\n",
    "- https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/html/100078_1.html\n",
    "- https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/xml/100078_1.xml\n",
    "\n",
    "The values are the according files, as bytestrings.\n",
    "\n",
    "Right now we care more about parseable data than readable pages,\n",
    "so we focus on the XML (also in the parsing helper functions), \n",
    "but also extract HTML for those that prefer it.\n",
    "We ignore anything else it might contain.\n",
    "\n",
    "Also, it seems that KOOP search results expose some variation in the capitalisation, led to duplicate URLs such as: \n",
    "- https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/xml/100078_1.xml\n",
    "- https://repository.officiele-overheidspublicaties.nl/cvdr/100078/1/xml/100078_1.xml\n",
    "\n",
    "...so we also ensure we pick just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The store had 904116 items, of which 0 not immediately relevant\n",
      "  Of the relevant ones, 295261 are XMLs, 291396 are (X)HMTLs. \n",
      "  (so approx 317459 seem to be case duplicates?)\n"
     ]
    }
   ],
   "source": [
    "# case insensitive choice.\n",
    "# (We previously had some tests that their contents are identical, and indeed found no difference)\n",
    "\n",
    "casededup_xml    = collections.defaultdict(list)  # lowercased version of URL -> actual URLs\n",
    "casededup_html   = collections.defaultdict(list)  # lowercased version of URL -> actual URLs\n",
    "ignore_list      = []\n",
    "\n",
    "unique_xml_urls  = []\n",
    "unique_html_urls = []\n",
    "\n",
    "for url in cvdr_fetched:\n",
    "    if url.endswith('.xml'):\n",
    "        casededup_xml[ url.lower() ].append( url )\n",
    "    elif url.endswith('.html'):\n",
    "        casededup_html[ url.lower() ].append( url )\n",
    "    else:\n",
    "        ignore_list.append( url )\n",
    "\n",
    "for lurl in list(casededup_xml):\n",
    "     url_list = sorted( casededup_xml[lurl] ) # sorting for some consistency in which one we pick - not necessary, but nice\n",
    "     unique_xml_urls.append( url_list[0] )\n",
    "\n",
    "for lurl in list(casededup_html):\n",
    "     url_list = sorted( casededup_html[lurl] ) \n",
    "     unique_html_urls.append( url_list[0] )\n",
    "\n",
    "# report\n",
    "print( f\"The store had {len(cvdr_fetched)} items, of which {len(ignore_list)} not immediately relevant\" )\n",
    "print( f\"  Of the relevant ones, {len( unique_xml_urls )} are XMLs, {len( unique_html_urls )} are (X)HMTLs. \" )\n",
    "print( f\"  (so approx %d seem to be case duplicates?)\"%(\n",
    "    len(cvdr_fetched) - ( len( unique_xml_urls ) + len( unique_html_urls ))    \n",
    ") )\n",
    "if len(ignore_list)>0:\n",
    "    print(\"some URLs are ignored include:\")\n",
    "    for url in random.sample( ignore_list, 10):\n",
    "        print( f'   {url}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group expressions by their work ID (remember, CVDR works have multiple expressions, e.g. 100078 is a work and 100078_1 its first expression/version)\n",
    "#   More specifically, we want to create a dict like:\n",
    "#     work_id -> [ {dict with version, xml_url, html_url}, ... ]\n",
    "#   We spend some extra code to be able to deal with the absence of html (but not xml)\n",
    "# ...and _then_ pick just the last\n",
    "\n",
    "def work_expression_in_url(url):\n",
    "    # fish IDs out of an URL like 'https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/xml/100078_1.xml'\n",
    "    ids                    = url.rsplit('/',1)[1].rsplit('.',1)[0]                # output would e.g. be '100078_1'\n",
    "    work_id, expression_id = wetsuite.helpers.koop_parse.cvdr_parse_identifier(ids)\n",
    "    version_int            = int( expression_id.split('_',1)[1], 10)   # as an integer, mainly for correct sorting\n",
    "    return work_id, expression_id, version_int                         # output would e.g. be ('100078', '100078_1', 1)\n",
    "\n",
    "\n",
    "group_collect = collections.defaultdict( lambda: collections.defaultdict(dict) ) # workid-> { expressionid: }\n",
    "\n",
    "for url in unique_xml_urls:\n",
    "    work_id, expression_id, version_int = work_expression_in_url( url )\n",
    "    group_collect[work_id][expression_id]['xml']     = url\n",
    "    group_collect[work_id][expression_id]['version'] = version_int\n",
    "\n",
    "for url in unique_html_urls:\n",
    "    work_id, expression_id, version_int = work_expression_in_url( url )\n",
    "    group_collect[work_id][expression_id]['html'] = url\n",
    "\n",
    "# now we can actually do that choice of the last from each\n",
    "lasts_only = {}\n",
    "for work_id in group_collect:\n",
    "#for work_id in list(group_collect)[10:11]:\n",
    "    versions_dict = list( group_collect[work_id].items() )\n",
    "    choice_key, choice_dict = sorted( versions_dict, key=lambda x:x[1]['version'])[-1] # details of last version\n",
    "    lasts_only[work_id] = (choice_dict['version'], choice_key, choice_dict.get('xml'), choice_dict.get('html') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a store that intends to contain just the most recent expression XML for each work.\n",
    "And the same for HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (may take a few minuets, just to write a few GB of data)\n",
    "cvdr_latestonly_xml = wetsuite.helpers.localdata.LocalKV( 'cvdr-mostrecent-xml.db', str, bytes )\n",
    "cvdr_latestonly_xml._put_meta('description_short',  'Raw XML for the latest expression within each CVDR work set')\n",
    "cvdr_latestonly_xml._put_meta('description',''' ''')\n",
    "\n",
    "cvdr_latestonly_html = wetsuite.helpers.localdata.LocalKV( 'cvdr-mostrecent-html.db', str, bytes )\n",
    "cvdr_latestonly_html._put_meta('description_short',  'Raw HTML for the latest expression within each CVDR work set')\n",
    "cvdr_latestonly_html._put_meta('description',''' ''')\n",
    "\n",
    "for work_id, (version, expr_id, xml_url, html_url) in wetsuite.helpers.notebook.ProgressBar( lasts_only.items() ):\n",
    "    cvdr_latestonly_xml.put( work_id, cvdr_fetched.get( xml_url ), commit=False )\n",
    "    if html_url is not None:\n",
    "        cvdr_latestonly_html.put( work_id, cvdr_fetched.get( html_url ), commit=False )\n",
    "\n",
    "cvdr_latestonly_xml.commit()\n",
    "cvdr_latestonly_html.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvdr_latestonly_xml.summary(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and stores that contain the plain text, and the metadata, for the same latest expressions. \n",
    "\n",
    "These three stores should have exactly the same keys (unless maybe we forget to clean the lastest leftoves betwen rerunning this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvdr_latestonly_text = wetsuite.helpers.localdata.LocalKV( 'cvdr-mostrecent-text.db', str, str )\n",
    "cvdr_latestonly_text._put_meta('description_short','Flattened plain text for the latest expression within each CVDR work set') \n",
    "cvdr_latestonly_text._put_meta('description',''' ''') \n",
    "\n",
    "cvdr_latestonly_meta = wetsuite.helpers.localdata.MsgpackKV( 'cvdr-mostrecent-meta-struc.db', str, None)\n",
    "cvdr_latestonly_meta._put_meta('description_short','Metadata for the latest expression within each CVDR work set') \n",
    "cvdr_latestonly_meta._put_meta('description',''' ''') \n",
    "\n",
    "\n",
    "unknown_xml = 0\n",
    "for work_id, xml_bytes in wetsuite.helpers.notebook.ProgressBar( cvdr_latestonly_xml.items() ):\n",
    "#for url in wetsuite.helpers.notebook.ProgressBar( list(cvdr_latestonly_xml.keys())[210000:] ):\n",
    "#        xml_bytes = cvdr_latestonly_xml.get( url )\n",
    "\n",
    "    tree = wetsuite.helpers.etree.fromstring( xml_bytes )\n",
    "        \n",
    "    if work_id not in cvdr_latestonly_meta:\n",
    "        try:\n",
    "                meta = wetsuite.helpers.koop_parse.cvdr_meta(tree, flatten=True)\n",
    "                cvdr_latestonly_meta.put(work_id, meta, commit=False)\n",
    "        except ValueError as ve: # probably us noticing we don't know a variant of XML\n",
    "                #print( f'{ve} for {url}' )\n",
    "                unknown_xml += 1\n",
    "                #pprint.pprint(meta)\n",
    "\n",
    "    if work_id not in cvdr_latestonly_text:\n",
    "        try:\n",
    "                text = wetsuite.helpers.koop_parse.cvdr_text(tree)\n",
    "                cvdr_latestonly_text.put(work_id, text, commit=False)\n",
    "        except AttributeError as ae:\n",
    "                #print( f'{ae} for {url}' )\n",
    "                unknown_xml += 1\n",
    "\n",
    "cvdr_latestonly_meta.commit()\n",
    "cvdr_latestonly_text.commit()\n",
    "\n",
    "unknown_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('119373',\n",
       "  {'identifier': 'CVDR119373_1',\n",
       "   'title': 'Besluit voorzieningen maatschappelijke ondersteuning gemeente Vlagtwedde 2011',\n",
       "   'language': 'nl',\n",
       "   'type': 'regeling (overheid:Informatietype)',\n",
       "   'creator': 'Vlagtwedde (overheid:Gemeente)',\n",
       "   'modified': '2017-09-05',\n",
       "   'spatial': 'Vlagtwedde (overheid:Gemeente)',\n",
       "   'isFormatOf': 'Ter Apeler Courant d.d. 24 augustus 2011 ()',\n",
       "   'alternative': 'Besluit voorzieningen maatschappelijke ondersteuning gemeente Vlagtwedde 2011',\n",
       "   'source': 'Geen ()',\n",
       "   'isRatifiedBy': 'college van burgemeester en wethouders (overheid:BestuursorgaanGemeente)',\n",
       "   'subject': 'maatschappelijke zorg en welzijn',\n",
       "   'issued': '2011-08-16',\n",
       "   'rights': 'De tekst in dit document is vrij van auteursrecht en\\n                    databankrecht',\n",
       "   'inwerkingtredingDatum': '2011-08-25',\n",
       "   'uitwerkingtredingDatum': '2011-12-31',\n",
       "   'betreft': 'Onbekend',\n",
       "   'kenmerk': 'ZA.11-12573',\n",
       "   'gedelegeerdeRegelgeving': 'Geen',\n",
       "   'redactioneleToevoeging': 'Geen'}),\n",
       " ('76510',\n",
       "  {'identifier': 'CVDR76510_1',\n",
       "   'title': 'FinanciÃ«le verordening gemeente Kaag en Braassem 2011',\n",
       "   'language': 'nl',\n",
       "   'type': 'regeling (overheid:Informatietype)',\n",
       "   'creator': 'Kaag en Braassem (overheid:Gemeente)',\n",
       "   'modified': '2017-10-17',\n",
       "   'spatial': 'Kaag en Braassem (overheid:Gemeente)',\n",
       "   'isFormatOf': 'Witte Weekblad, 22-12-2010 ()',\n",
       "   'alternative': 'FinanciÃ«le verordening gemeente Kaag en Braassem 2011',\n",
       "   'source': 'Gemeentewet, art. 212 (http://wetten.overheid.nl/BWBR0005416/TitelIV/HoofdstukXIV/Artikel212)',\n",
       "   'isRatifiedBy': 'gemeenteraad (overheid:BestuursorgaanGemeente)',\n",
       "   'subject': 'financiÃ«n en economie',\n",
       "   'issued': '2010-12-13',\n",
       "   'rights': 'De tekst in dit document is vrij van auteursrecht en\\n                    databankrecht',\n",
       "   'inwerkingtredingDatum': '2010-12-23',\n",
       "   'uitwerkingtredingDatum': '2014-09-01',\n",
       "   'betreft': 'Nieuwe regeling',\n",
       "   'kenmerk': '10.107',\n",
       "   'gedelegeerdeRegelgeving': 'Geen',\n",
       "   'redactioneleToevoeging': 'Regeling vervangt FinanciÃ«le verordening Kaag en Braassem van 04-10-2010.'}),\n",
       " ('492303',\n",
       "  {'identifier': 'CVDR492303_1',\n",
       "   'title': 'Verordening van de gemeenteraad van de gemeente Kollumerland c.a. houdende regels omtrent rioolheffing Verordening rioolheffing 2019',\n",
       "   'language': 'nl',\n",
       "   'type': 'regeling (overheid:Informatietype)',\n",
       "   'creator': 'Kollumerland en Nieuwkruisland (overheid:Gemeente)',\n",
       "   'modified': '2018-12-31',\n",
       "   'spatial': 'Kollumerland en Nieuwkruisland (overheid:Gemeente)',\n",
       "   'isFormatOf': 'Gemeenteblad 2018, 282199 (https://zoek.officielebekendmakingen.nl/gmb-2018-282199.html)',\n",
       "   'alternative': 'Verordening rioolheffing 2019',\n",
       "   'source': 'artikel 216 Gemeentewet (1.0:v:BWBR0005416&artikel=216),  artikel 219 Gemeentewet (1.0:v:BWBR0005416&artikel=219),  artikel 228a Gemeentewet (1.0:v:BWBR0005416&artikel=228a)',\n",
       "   'isRatifiedBy': 'gemeenteraad (overheid:BestuursorgaanGemeente)',\n",
       "   'subject': 'financiÃ«n en economie',\n",
       "   'issued': '2018-11-01',\n",
       "   'rights': 'De tekst in dit document is vrij van auteursrecht en\\n                    databankrecht',\n",
       "   'inwerkingtredingDatum': '2018-12-29',\n",
       "   'uitwerkingtredingDatum': '2019-02-09',\n",
       "   'betreft': 'nieuwe regeling',\n",
       "   'kenmerk': '.',\n",
       "   'redactioneleToevoeging': 'Deze regeling vervangt deVerordening op de heffing en de invordering van rioolheffing 2018.De datum van ingang van heffing is 31 december 2018.'})]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examples of the metadata\n",
    "cvdr_latestonly_meta.random_sample(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
