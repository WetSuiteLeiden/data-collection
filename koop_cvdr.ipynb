{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/WetSuiteLeiden/data-collection/blob/master/koop_cvdr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "Show how we fetch data from the CVDR repository to be used to create our corresponding datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import random\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "import wetsuite.helpers.notebook\n",
    "import wetsuite.helpers.localdata\n",
    "import wetsuite.datacollect.koop_sru \n",
    "import wetsuite.helpers.date\n",
    "import wetsuite.helpers.etree\n",
    "import wetsuite.helpers.koop_parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store to put downloads into:\n",
    "cvdr_fetched = wetsuite.helpers.localdata.LocalKV( 'cvdr_fetched.db', str, bytes )\n",
    "\n",
    "# out of interest  (can take a few seconds once it's large, because get_num_items walks through everything)\n",
    "#cvdr_fetched.summary(get_num_items=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dcterms.modified >= 2024-03-09']\n"
     ]
    }
   ],
   "source": [
    "# no fancy queries, just date ranges\n",
    "queries = []\n",
    "\n",
    "if 0: \n",
    "    # split many years into shorter spans, to do many fetches in smaller chunks\n",
    "    #   (for reference, there are usually 20 to 250 items per day)\n",
    "    for from_date, to_date in wetsuite.helpers.date.date_ranges( from_date=datetime.date( 2000, 1, 1 ),  to_date=datetime.date.today(), increment_days=50, strftime_format=\"%Y-%m-%d\" ):\n",
    "        queries.append( f'dcterms.modified>={from_date} and dcterms.modified<={to_date}' ) # TODO: check whether there is a better field than modified\n",
    "\n",
    "else:\n",
    "    # ask for recent changes \n",
    "    #   (note: we treat this as \"fetch documents that were mentioned\", \n",
    "    #          not as a \"re-fetch things that were changed\" )\n",
    "    some_time_ago = datetime.date.today() - datetime.timedelta( days=72 )\n",
    "    queries.append( f'dcterms.modified >= {some_time_ago.strftime(\"%Y-%m-%d\")}' )\n",
    "\n",
    "print( queries )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post those queries, fetch any referenced documents we didn't already have\n",
    "\n",
    "sru_cvdr = wetsuite.datacollect.koop_sru.CVDR()\n",
    "\n",
    "for query in queries:\n",
    "    print( f'Search: {query}' )\n",
    "    sru_cvdr.search_retrieve( query ) # purely for the number of records, itself only for the progress bar\n",
    "    numrecs = sru_cvdr.num_records()\n",
    "    pbar = wetsuite.helpers.notebook.progress_bar( numrecs, description='fetching' )\n",
    "\n",
    "    count_cached, count_fetched, count_error = 0, 0, 0\n",
    "\n",
    "    def cvdr_callback( record_node ):\n",
    "        ''' Read search result records, pick out the URLs to fetch and fetch them. \n",
    "            Is a local function because we count per query, in a slightly weirdly scoped way '''\n",
    "        #print( wetsuite.helpers.etree.debug_pretty( record_node ) ) # for later reference, if you want to extract more out of these search records\n",
    "        global count_cached, count_fetched, count_error\n",
    "\n",
    "        merged = wetsuite.helpers.koop_parse.cvdr_meta( record_node, flatten=True ) \n",
    "        # using flatten is a little creative for something that needs to be a precise value (see cvdr_meta's docstring) but in current use it is valid.\n",
    "        #pprint.pprint( merged )\n",
    "\n",
    "        for resource_name, resource_key in ( \n",
    "            ('XML',  'publicatieurl_xml'),\n",
    "            ('HTML', 'publicatieurl_xhtml'),\n",
    "        ):\n",
    "            if resource_key not in merged:\n",
    "                print('SKIP: no %r in %r'%(resource_key, merged))\n",
    "            else:\n",
    "                try:\n",
    "                    _, came_from_cache = wetsuite.helpers.localdata.cached_fetch( cvdr_fetched, merged[ resource_key] ) # we currently care only about the XML it links to\n",
    "                    if not came_from_cache:\n",
    "                        count_fetched += 1\n",
    "                        time.sleep( 2 ) # be somewhat nice to the servers\n",
    "                    else:\n",
    "                        count_cached += 1\n",
    "                # mainly expecting 404, 500\n",
    "                except ValueError as e:\n",
    "                    count_error += 1\n",
    "                    print( \"ERROR downloading %s: %s  for %r\"%(resource_name, e, merged[resource_key]))\n",
    "                    time.sleep( 10 ) # be somewhat nicer to the servers\n",
    "\n",
    "        pbar.value       += 1\n",
    "        pbar.description  = f'{count_fetched} fetched, {count_cached} cached' # , {count_error} errors\n",
    "\n",
    "    try:\n",
    "        sru_cvdr.search_retrieve_many( query, at_a_time=500, up_to=50000, callback=cvdr_callback)\n",
    "\n",
    "    except ValueError as e:\n",
    "        count_error += 1\n",
    "        print( \"ERROR querying %s: %s\"%(query, e) )\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset\n",
    "\n",
    "We'll spare you the full contents of that store,\n",
    "because it contains most versions of most things, \n",
    "is even more overcomplete than that because of past experiments,\n",
    "and probably not something you want to fetch yourself for the sheer size of it.\n",
    "\n",
    "Mostly for our own reference, it contains keys that are URLs like:\n",
    "- https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/html/100078_1.html\n",
    "- https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/xml/100078_1.xml\n",
    "\n",
    "The values are the according files, as bytestrings.\n",
    "\n",
    "Right now we care more about parseable data than readable pages,\n",
    "so we focus on the XML (also in the parsing helper functions), \n",
    "but also extract HTML for those that prefer it.\n",
    "We ignore anything else it might contain.\n",
    "\n",
    "Also, it seems that KOOP search results expose some variation in the capitalisation, led to duplicate URLs in the above, e.g. \n",
    "- https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/xml/100078_1.xml\n",
    "- https://repository.officiele-overheidspublicaties.nl/cvdr/100078/1/xml/100078_1.xml\n",
    "\n",
    "...so we also ensure we pick just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The store had 884010 items, of which 0 not immediately relevant\n",
      "  Of the relevant ones, 283946 are XMLs, 282605 are (X)HMTLs. \n",
      "  (so approx 317459 seem to be case duplicates?)\n"
     ]
    }
   ],
   "source": [
    "# case insensitive choice.\n",
    "# (We previously had some tests that their contents are identical, and indeed found no difference)\n",
    "\n",
    "casededup_xml   = collections.defaultdict(list)  # lowercased version of URL -> actual URLs\n",
    "casededup_html  = collections.defaultdict(list)  # lowercased version of URL -> actual URLs\n",
    "ignore_list     = []\n",
    "\n",
    "unique_xml_urls = []\n",
    "unique_html_urls = []\n",
    "\n",
    "for url in cvdr_fetched:\n",
    "    if url.endswith('.xml'):\n",
    "        casededup_xml[ url.lower() ].append( url )\n",
    "    elif url.endswith('.html'):\n",
    "        casededup_html[ url.lower() ].append( url )\n",
    "    else:\n",
    "        ignore_list.append( url )\n",
    "\n",
    "for lurl in list(casededup_xml):\n",
    "     url_list = sorted( casededup_xml[lurl] ) # sorting for some consistency in which one we pick - not necessary, but nice\n",
    "     unique_xml_urls.append( url_list[0] )\n",
    "\n",
    "for lurl in list(casededup_html):\n",
    "     url_list = sorted( casededup_html[lurl] ) \n",
    "     unique_html_urls.append( url_list[0] )\n",
    "\n",
    "# report\n",
    "print( f\"The store had {len(cvdr_fetched)} items, of which {len(ignore_list)} not immediately relevant\" )\n",
    "print( f\"  Of the relevant ones, {len( unique_xml_urls )} are XMLs, {len( unique_html_urls )} are (X)HMTLs. \" )\n",
    "print( f\"  (so approx %d seem to be case duplicates?)\"%(\n",
    "    len(cvdr_fetched) - ( len( unique_xml_urls ) + len( unique_html_urls ))    \n",
    ") )\n",
    "if len(ignore_list)>0:\n",
    "    print(\"some URLs are ignored include:\")\n",
    "    for url in random.sample( ignore_list, 10):\n",
    "        print( f'   {url}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group expressions by their work ID. More specifically, we want to create a dict like:\n",
    "#   work_id -> expression_id [ dict with version, xml_url, html_url), ... ]\n",
    "# We spend some extra time to be able to deal with the absence of html (but not xml)\n",
    "# ...and _then_ pick just the last\n",
    "\n",
    "def work_expression_in_url(url):\n",
    "    # fish IDs out of an URL like 'https://repository.officiele-overheidspublicaties.nl/CVDR/100078/1/xml/100078_1.xml'\n",
    "    ids                    = url.rsplit('/',1)[1].rsplit('.',1)[0]                # output would e.g. be '100078_1'\n",
    "    work_id, expression_id = wetsuite.helpers.koop_parse.cvdr_parse_identifier(ids)\n",
    "    version_int            = int( expression_id.split('_',1)[1], 10)   # as an integer, mainly for correct sorting\n",
    "    return work_id, expression_id, version_int                         # output would e.g. be ('100078', '100078_1', 1)\n",
    "\n",
    "\n",
    "group_collect = collections.defaultdict( lambda: collections.defaultdict(dict) ) # workid-> { expressionid: }\n",
    "\n",
    "for url in unique_xml_urls:\n",
    "    work_id, expression_id, version_int = work_expression_in_url( url )\n",
    "    group_collect[work_id][expression_id]['xml']     = url\n",
    "    group_collect[work_id][expression_id]['version'] = version_int\n",
    "\n",
    "for url in unique_html_urls:\n",
    "    work_id, expression_id, version_int = work_expression_in_url( url )\n",
    "    group_collect[work_id][expression_id]['html'] = url\n",
    "\n",
    "# now we can actually do that choice of the last from each\n",
    "lasts_only = {}\n",
    "for work_id in group_collect:\n",
    "#for work_id in list(group_collect)[10:11]:\n",
    "    versions_dict = list( group_collect[work_id].items() )\n",
    "    choice_key, choice_dict = sorted( versions_dict, key=lambda x:x[1]['version'])[-1] # details of last version\n",
    "    lasts_only[work_id] = (choice_dict['version'], choice_key, choice_dict.get('xml'), choice_dict.get('html') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a store that intends to contain just the most recent expression XML for each work.\n",
    "And the same for HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009493112564086914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 236967,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a732b06da7e4338a0b5260f8a2778bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236967 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# takes minute or to just to write that much data  (order of a few GB)\n",
    "cvdr_latestonly_xml = wetsuite.helpers.localdata.LocalKV( 'cvdr-mostrecent-xml.db', str, bytes )\n",
    "cvdr_latestonly_xml._put_meta('description_short',  'Raw XML for the latest expression within each CVDR work set')\n",
    "cvdr_latestonly_xml._put_meta('description',''' ''')\n",
    "\n",
    "cvdr_latestonly_html = wetsuite.helpers.localdata.LocalKV( 'cvdr-mostrecent-html.db', str, bytes )\n",
    "cvdr_latestonly_html._put_meta('description_short',  'Raw HTML for the latest expression within each CVDR work set')\n",
    "cvdr_latestonly_html._put_meta('description',''' ''')\n",
    "\n",
    "for work_id, (version, expr_id, xml_url, html_url) in wetsuite.helpers.notebook.ProgressBar( lasts_only.items() ):\n",
    "    cvdr_latestonly_xml.put( work_id, cvdr_fetched.get( xml_url ), commit=False )\n",
    "    if html_url is not None:\n",
    "        cvdr_latestonly_html.put( work_id, cvdr_fetched.get( html_url ), commit=False )\n",
    "\n",
    "cvdr_latestonly_xml.commit()\n",
    "cvdr_latestonly_html.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size_bytes': 9371648,\n",
       " 'size_readable': '9.4M',\n",
       " 'num_items': 1,\n",
       " 'avgsize_bytes': 9371648}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvdr_latestonly_xml.summary(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and stores that contain the plain text, and the metadata, for the same latest expressions. \n",
    "\n",
    "These three stores should have exactly the same keys (unless maybe we forget to clean the lastest leftoves betwen rerunning this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012218236923217773,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 236967,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2775a2c6b94db7a4fcadccf2142ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236967 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvdr_latestonly_text = wetsuite.helpers.localdata.LocalKV( 'cvdr-mostrecent-text.db', str, str )\n",
    "cvdr_latestonly_text._put_meta('description_short','Flattened plain text for the latest expression within each CVDR work set') \n",
    "cvdr_latestonly_text._put_meta('description',''' ''') \n",
    "\n",
    "cvdr_latestonly_meta = wetsuite.helpers.localdata.MsgpackKV( 'cvdr-mostrecent-meta-struc.db', str, None)\n",
    "cvdr_latestonly_meta._put_meta('description_short','Metadata for the latest expression within each CVDR work set') \n",
    "cvdr_latestonly_meta._put_meta('description',''' ''') \n",
    "\n",
    "\n",
    "unknown_xml = 0\n",
    "for work_id, xml_bytes in wetsuite.helpers.notebook.ProgressBar( cvdr_latestonly_xml.items() ):\n",
    "#for url in wetsuite.helpers.notebook.ProgressBar( list(cvdr_latestonly_xml.keys())[210000:] ):\n",
    "#        xml_bytes = cvdr_latestonly_xml.get( url )\n",
    "\n",
    "    tree = wetsuite.helpers.etree.fromstring( xml_bytes )\n",
    "        \n",
    "    if work_id not in cvdr_latestonly_meta:\n",
    "        try:\n",
    "                meta = wetsuite.helpers.koop_parse.cvdr_meta(tree, flatten=True)\n",
    "                cvdr_latestonly_meta.put(work_id, meta, commit=False)\n",
    "        except ValueError as ve: # probably us noticing we don't know a variant of XML\n",
    "                #print( f'{ve} for {url}' )\n",
    "                unknown_xml += 1\n",
    "                #pprint.pprint(meta)\n",
    "\n",
    "    if work_id not in cvdr_latestonly_text:\n",
    "        try:\n",
    "                text = wetsuite.helpers.koop_parse.cvdr_text(tree)\n",
    "                cvdr_latestonly_text.put(work_id, text, commit=False)\n",
    "        except AttributeError as ae:\n",
    "                #print( f'{ae} for {url}' )\n",
    "                unknown_xml += 1\n",
    "\n",
    "cvdr_latestonly_meta.commit()\n",
    "cvdr_latestonly_text.commit()\n",
    "\n",
    "unknown_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('119373',\n",
       "  {'identifier': 'CVDR119373_1',\n",
       "   'title': 'Besluit voorzieningen maatschappelijke ondersteuning gemeente Vlagtwedde 2011',\n",
       "   'language': 'nl',\n",
       "   'type': 'regeling (overheid:Informatietype)',\n",
       "   'creator': 'Vlagtwedde (overheid:Gemeente)',\n",
       "   'modified': '2017-09-05',\n",
       "   'spatial': 'Vlagtwedde (overheid:Gemeente)',\n",
       "   'isFormatOf': 'Ter Apeler Courant d.d. 24 augustus 2011 ()',\n",
       "   'alternative': 'Besluit voorzieningen maatschappelijke ondersteuning gemeente Vlagtwedde 2011',\n",
       "   'source': 'Geen ()',\n",
       "   'isRatifiedBy': 'college van burgemeester en wethouders (overheid:BestuursorgaanGemeente)',\n",
       "   'subject': 'maatschappelijke zorg en welzijn',\n",
       "   'issued': '2011-08-16',\n",
       "   'rights': 'De tekst in dit document is vrij van auteursrecht en\\n                    databankrecht',\n",
       "   'inwerkingtredingDatum': '2011-08-25',\n",
       "   'uitwerkingtredingDatum': '2011-12-31',\n",
       "   'betreft': 'Onbekend',\n",
       "   'kenmerk': 'ZA.11-12573',\n",
       "   'gedelegeerdeRegelgeving': 'Geen',\n",
       "   'redactioneleToevoeging': 'Geen'}),\n",
       " ('76510',\n",
       "  {'identifier': 'CVDR76510_1',\n",
       "   'title': 'Financiële verordening gemeente Kaag en Braassem 2011',\n",
       "   'language': 'nl',\n",
       "   'type': 'regeling (overheid:Informatietype)',\n",
       "   'creator': 'Kaag en Braassem (overheid:Gemeente)',\n",
       "   'modified': '2017-10-17',\n",
       "   'spatial': 'Kaag en Braassem (overheid:Gemeente)',\n",
       "   'isFormatOf': 'Witte Weekblad, 22-12-2010 ()',\n",
       "   'alternative': 'Financiële verordening gemeente Kaag en Braassem 2011',\n",
       "   'source': 'Gemeentewet, art. 212 (http://wetten.overheid.nl/BWBR0005416/TitelIV/HoofdstukXIV/Artikel212)',\n",
       "   'isRatifiedBy': 'gemeenteraad (overheid:BestuursorgaanGemeente)',\n",
       "   'subject': 'financiën en economie',\n",
       "   'issued': '2010-12-13',\n",
       "   'rights': 'De tekst in dit document is vrij van auteursrecht en\\n                    databankrecht',\n",
       "   'inwerkingtredingDatum': '2010-12-23',\n",
       "   'uitwerkingtredingDatum': '2014-09-01',\n",
       "   'betreft': 'Nieuwe regeling',\n",
       "   'kenmerk': '10.107',\n",
       "   'gedelegeerdeRegelgeving': 'Geen',\n",
       "   'redactioneleToevoeging': 'Regeling vervangt Financiële verordening Kaag en Braassem van 04-10-2010.'}),\n",
       " ('492303',\n",
       "  {'identifier': 'CVDR492303_1',\n",
       "   'title': 'Verordening van de gemeenteraad van de gemeente Kollumerland c.a. houdende regels omtrent rioolheffing Verordening rioolheffing 2019',\n",
       "   'language': 'nl',\n",
       "   'type': 'regeling (overheid:Informatietype)',\n",
       "   'creator': 'Kollumerland en Nieuwkruisland (overheid:Gemeente)',\n",
       "   'modified': '2018-12-31',\n",
       "   'spatial': 'Kollumerland en Nieuwkruisland (overheid:Gemeente)',\n",
       "   'isFormatOf': 'Gemeenteblad 2018, 282199 (https://zoek.officielebekendmakingen.nl/gmb-2018-282199.html)',\n",
       "   'alternative': 'Verordening rioolheffing 2019',\n",
       "   'source': 'artikel 216 Gemeentewet (1.0:v:BWBR0005416&artikel=216),  artikel 219 Gemeentewet (1.0:v:BWBR0005416&artikel=219),  artikel 228a Gemeentewet (1.0:v:BWBR0005416&artikel=228a)',\n",
       "   'isRatifiedBy': 'gemeenteraad (overheid:BestuursorgaanGemeente)',\n",
       "   'subject': 'financiën en economie',\n",
       "   'issued': '2018-11-01',\n",
       "   'rights': 'De tekst in dit document is vrij van auteursrecht en\\n                    databankrecht',\n",
       "   'inwerkingtredingDatum': '2018-12-29',\n",
       "   'uitwerkingtredingDatum': '2019-02-09',\n",
       "   'betreft': 'nieuwe regeling',\n",
       "   'kenmerk': '.',\n",
       "   'redactioneleToevoeging': 'Deze regeling vervangt deVerordening op de heffing en de invordering van rioolheffing 2018.De datum van ingang van heffing is 31 december 2018.'})]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examples of the metadata\n",
    "cvdr_latestonly_meta.random_sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: See if there is anyything useful in the below that should go above\n",
    "\n",
    "\n",
    "indat  = meta.get('inwerkingtredingDatum')\n",
    "if indat is not None:\n",
    "    indat = indat[0]['text']\n",
    "if indat is not None:\n",
    "    #print(indat)\n",
    "    indat = parse_date( indat )\n",
    "\n",
    "uitdat = meta.get('uitwerkingtredingDatum')\n",
    "if uitdat is not None: \n",
    "    uitdat = uitdat[0]['text']\n",
    "if uitdat is not None: \n",
    "    #print(uitdat)\n",
    "    uitdat = parse_date( uitdat )\n",
    "\n",
    "###  \n",
    "# collect things into a dict\n",
    "doc = {\n",
    "    'xml_url':url, \n",
    "    'web_url':'https://lokaleregelgeving.overheid.nl/CVDR%s'%( expression_id.replace('_','/') ) # presumably?\n",
    "}\n",
    "\n",
    "doc['title']      = meta.get('title')[0]['text'] # assumes there's always exactly one\n",
    "\n",
    "for fetch_as_list in (\n",
    "        'alternative', 'subject', 'issued', 'modified', 'onderwerp','betreft',\n",
    "        'inwerkingtredingDatum', 'uitwerkingtredingDatum', \n",
    "        'kenmerk', 'redactioneleToevoeging',\n",
    "    ):\n",
    "    dict_list = meta.get(fetch_as_list)\n",
    "    if dict_list is not None:\n",
    "        doc[fetch_as_list] = []\n",
    "        for d in dict_list:\n",
    "            dtext = d.get('text')\n",
    "            if dtext is not None:\n",
    "                doc[fetch_as_list].append( dtext )\n",
    "\n",
    "for fetch_as_list_with_attr in ( \n",
    "        ('creator', 'scheme'),\n",
    "        ('spatial', 'scheme'),\n",
    "        ('isRatifiedBy', 'scheme'),\n",
    "        ('source', 'resourceIdentifier'),\n",
    "        ('isFormatOf', 'resourceIdentifier'),\n",
    "    ):\n",
    "    want_key, want_attrkey = fetch_as_list_with_attr\n",
    "    dict_list = meta.get(want_key)\n",
    "    if dict_list is not None:\n",
    "        doc[want_key] = []\n",
    "        for d in dict_list:\n",
    "            dtext = d.get('text')\n",
    "            if dtext is not None:\n",
    "                attr  = d.get('attr')\n",
    "                if want_attrkey in attr:\n",
    "                    doc[want_key].append( (attr.get(want_attrkey), dtext) )\n",
    "\n",
    "\n",
    "# for 'print what haven't I handled yet' purposes:\n",
    "for rem in ['title', 'alternative', 'subject', 'issued', 'modified',\n",
    "            'language', 'format', 'rights', 'identifier', 'type',\n",
    "            'creator', 'spatial', 'isRatifiedBy', 'source', 'isFormatOf',\n",
    "            'onderwerp','betreft', 'kenmerk', 'redactioneleToevoeging',\n",
    "            'inwerkingtredingDatum', 'uitwerkingtredingDatum', \n",
    "            ]:\n",
    "    if rem in meta:\n",
    "        meta.pop(rem)\n",
    "\n",
    "text = wetsuite.helpers.koop_parse.cvdr_text( tree )\n",
    "doc['text']       = text\n",
    "\n",
    "#pprint.pprint( doc )\n",
    "\n",
    "def tuple_or_none(val):\n",
    "    ' '\n",
    "    if val is not None:\n",
    "        val = tuple(v  for v in val)\n",
    "    return val\n",
    "\n",
    "def get_tuple_or_none(key, join_if_sequence=' '):\n",
    "    ' '\n",
    "    val = doc.get(key)\n",
    "    ret = []\n",
    "    if val is not None:\n",
    "        for item in val:\n",
    "            if type(item) in (list, tuple):\n",
    "                ret.append( join_if_sequence.join(item) )\n",
    "            else:\n",
    "                ret.append( item )\n",
    "    return ret\n",
    "\n",
    "#print( inwerkingtreding )\n",
    "\n",
    "alternative            = get_tuple_or_none( 'alternative' )\n",
    "inwerkingtredingDatum  = tuple_or_none( doc.get( 'inwerkingtredingDatum'  ) )\n",
    "uitwerkingtredingDatum = tuple_or_none( doc.get( 'uitwerkingtredingDatum' ) )\n",
    "issued                 = get_tuple_or_none( 'issued' )\n",
    "subject                = get_tuple_or_none( 'subject' )\n",
    "creator                = get_tuple_or_none( 'creator' )\n",
    "spatial                = get_tuple_or_none( 'spatial' )\n",
    "\n",
    "curs2.execute('''INSERT INTO cvdr  (work_id, expression_id, title, alternative, inwerkingtreding, uitwerkingtreding, \n",
    "                                    issued, subject, creator, spatial, web_url, xml_url, plaintext)\n",
    "                    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)''', (\n",
    "    work_id, expression_id,  doc['title'], alternative, inwerkingtredingDatum, uitwerkingtredingDatum,\n",
    "    issued, subject, creator, spatial, doc['web_url'], doc['xml_url'], text,\n",
    ") )\n",
    "\n",
    "count+=1\n",
    "if count%1000==0:\n",
    "    conn2.commit()\n",
    "    gc.collect()\n",
    "\n",
    "conn2.commit()\n",
    "\n",
    "\n",
    "#with open('cvdr.json','w', encoding='utf8') as f:\n",
    "#    f.write( json.dumps(dataset) )\n",
    "\n",
    "\n",
    "if 0:\n",
    "\n",
    "    if 0:\n",
    "        for resource_name, dds in meta.items():\n",
    "            print( resource_name, dds)\n",
    "            for dd in dds:\n",
    "                text = dd.get('text')\n",
    "                if text is None:\n",
    "                    print('text is None for %r'%dd)\n",
    "                    continue\n",
    "                tlow = text.lower()\n",
    "\n",
    "                #attr = dd.get('attr')\n",
    "                #def normalize_isformatof(text):\n",
    "\n",
    "                if resource_name in ('isFormatOf',):\n",
    "                    if tlow.startswith('wsb-'):\n",
    "                        pass\n",
    "                    elif tlow.startswith('gmb-'):\n",
    "                        pass\n",
    "                    elif tlow.startswith('prb-'):\n",
    "                        pass\n",
    "                    elif tlow.startswith('bgr-'):\n",
    "                        pass\n",
    "                    elif tlow.startswith('stcrt-'):\n",
    "                        pass\n",
    "                    elif tlow.startswith('gemeenteblad'):\n",
    "                        pass # TODO: parse \n",
    "                    elif tlow.startswith('digitaal gemeenteblad'):\n",
    "                        pass # TODO: parse \n",
    "                    elif tlow.startswith('elektronisch gemeenteblad'):\n",
    "                        pass # TODO: parse \n",
    "                    elif tlow.startswith('waterschapsblad'):\n",
    "                        pass # TODO: parse \n",
    "                    elif tlow.startswith('provinciaal blad'):\n",
    "                        pass # TODO: parse \n",
    "                    #else:\n",
    "                    #    print(\"TODO: handle isFormatOf %r\"%text)\n",
    "\n",
    "    if 0:\n",
    "        refs = wetsuite.helpers.koop_parse.cvdr_sourcerefs( tree )\n",
    "        if len(refs)>0:\n",
    "            doc['refs'] = []\n",
    "            for typ, raw, bwb, params, reftext in refs:\n",
    "                #print( [typ, raw,bwb,params,reftext] )\n",
    "                if typ=='BWB':\n",
    "                    shortref = bwb\n",
    "                    #print(params)\n",
    "                    if 'hoofdstuk' in params:\n",
    "                        shortref += ' hoofdstuk '+params['hoofdstuk'][0]\n",
    "                    if 'artikel' in params:\n",
    "                        shortref += ' artikel '+params['artikel'][0]\n",
    "                    if 'lid' in params:\n",
    "                        shortref += ' lid '+params['lid'][0]\n",
    "\n",
    "                    if 1:\n",
    "                        print('RAW:      %s'%raw)\n",
    "                        print('BWB-ID:   %s'%bwb)\n",
    "                        print('PARAMS:   %s'%params)\n",
    "                        print('SHORTREF: %s'%shortref)\n",
    "                        print('TEXT:     %s'%reftext)\n",
    "                        print('')\n",
    "                    for k in params:\n",
    "                        params[k]=params[k][0] # probably usually good enough\n",
    "                    doc['refs'].append( (bwb, params, reftext) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
